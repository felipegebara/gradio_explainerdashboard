{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#analise do case de rh base do https://www.kaggle.com/mzinic/employee-churn-prediction?select=employee_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando a base\n",
    "\n",
    "data=pd.read_csv('employee_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['resposta']=np.where(data['status']=='Left',1,0)\n",
    "\n",
    "data = pd.get_dummies(data, columns = ['department'])\n",
    "data ['last_evaluation'] = data ['last_evaluation']. fillna (0)\n",
    "data['new']=np.where(data ['last_evaluation'] ==0,1,0)\n",
    "data ['filed_complaint'] = data ['filed_complaint']. fillna (0)\n",
    "data = pd.get_dummies(data, columns = ['salary'])\n",
    "\n",
    "data ['recently_promoted'] = data ['recently_promoted']. fillna (0)\n",
    "\n",
    "data ['satisfaction'] = data ['satisfaction']. fillna (data ['satisfaction'].mean())\n",
    "\n",
    "#tenure                                 \n",
    "data ['tenure'] = data ['tenure']. fillna (data ['tenure'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_monthly_hrs                      0\n",
       "filed_complaint                      0\n",
       "last_evaluation                      0\n",
       "n_projects                           0\n",
       "recently_promoted                    0\n",
       "satisfaction                         0\n",
       "status                               0\n",
       "tenure                               0\n",
       "resposta                             0\n",
       "department_IT                        0\n",
       "department_admin                     0\n",
       "department_engineering               0\n",
       "department_finance                   0\n",
       "department_information_technology    0\n",
       "department_management                0\n",
       "department_marketing                 0\n",
       "department_procurement               0\n",
       "department_product                   0\n",
       "department_sales                     0\n",
       "department_support                   0\n",
       "department_temp                      0\n",
       "new                                  0\n",
       "salary_high                          0\n",
       "salary_low                           0\n",
       "salary_medium                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_cols = [\n",
    "'avg_monthly_hrs',\n",
    "'filed_complaint',\n",
    "'last_evaluation',\n",
    "'n_projects',     \n",
    "'recently_promoted',\n",
    "'salary_high',           \n",
    "'salary_low',           \n",
    "'salary_high',           \n",
    "'salary_medium',\n",
    "    'satisfaction',     \n",
    "'tenure',           \n",
    "'department_IT',    \n",
    "'department_admin', \n",
    "'department_engineering',\n",
    "'department_finance',               \n",
    "'department_information_technology',\n",
    "'department_management',          \n",
    "'department_marketing',                \n",
    "'department_procurement',               \n",
    "'department_product',                   \n",
    "'department_sales',                     \n",
    "'department_support',                   \n",
    "'department_temp',                      \n",
    "'new']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features in the green area: ['avg_monthly_hrs', 'last_evaluation', 'n_projects', 'satisfaction']\n",
      "features in the blue area: []\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "###initialize Boruta\n",
    "\n",
    "X2=data[feature_cols].values\n",
    "\n",
    "y= ((data['resposta']).values)\n",
    "\n",
    "forest = RandomForestRegressor(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 3\n",
    ")\n",
    "boruta = BorutaPy(\n",
    "   estimator = forest, \n",
    "   n_estimators = 'auto',\n",
    "   max_iter = 100 # number of trials to perform\n",
    ")\n",
    "### fit Boruta (it accepts np.array, not pd.DataFrame)\n",
    "boruta.fit(X2,y)\n",
    "### print results\n",
    "green_area = data[feature_cols].columns[boruta.support_].to_list()\n",
    "blue_area = data[feature_cols].columns[boruta.support_weak_].to_list()\n",
    "print('features in the green area:', green_area)\n",
    "print('features in the blue area:', blue_area)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistica \n",
    "from sklearn.model_selection import train_test_split\n",
    "feature_cols = [\n",
    "'avg_monthly_hrs', 'last_evaluation', 'n_projects', 'satisfaction'\n",
    "]\n",
    "X=data[feature_cols]\n",
    "\n",
    "y=data['resposta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fgeba\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning:\n",
      "\n",
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "model = XGBClassifier(max_depth=3,n_estimators=20)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2160   40]\n",
      " [ 119  531]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      2200\n",
      "           1       0.93      0.82      0.87       650\n",
      "\n",
      "    accuracy                           0.94      2850\n",
      "   macro avg       0.94      0.90      0.92      2850\n",
      "weighted avg       0.94      0.94      0.94      2850\n",
      "\n",
      "0.9442105263157895\n",
      "R^2 Training Score: 0.94  \n",
      "R^2 Validation Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print('R^2 Training Score: {:.2f}  \\nR^2 Validation Score: {:.2f}'.format(model.score(X_train, y_train), \n",
    "                                                                                        \n",
    "                                                                                             model.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks(data=None,target=None, prob=None):\n",
    "    data['target0'] = 1 - data[target]\n",
    "    data['bucket'] = pd.qcut(data[prob], 10)\n",
    "    grouped = data.groupby('bucket', as_index = False)\n",
    "    kstable = pd.DataFrame()\n",
    "    kstable['min_prob'] = grouped.min()[prob]\n",
    "    kstable['max_prob'] = grouped.max()[prob]\n",
    "    kstable['events']   = grouped.sum()[target]\n",
    "    kstable['nonevents'] = grouped.sum()['target0']\n",
    "    kstable = kstable.sort_values(by=\"min_prob\", ascending=False).reset_index(drop = True)\n",
    "    kstable['event_rate'] = (kstable.events / data[target].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['nonevent_rate'] = (kstable.nonevents / data['target0'].sum()).apply('{0:.2%}'.format)\n",
    "    kstable['cum_eventrate']=(kstable.events / data[target].sum()).cumsum()\n",
    "    kstable['cum_noneventrate']=(kstable.nonevents / data['target0'].sum()).cumsum()\n",
    "    kstable['KS'] = np.round(kstable['cum_eventrate']-kstable['cum_noneventrate'], 3) * 100\n",
    "\n",
    "    #Formating\n",
    "    kstable['cum_eventrate']= kstable['cum_eventrate'].apply('{0:.2%}'.format)\n",
    "    kstable['cum_noneventrate']= kstable['cum_noneventrate'].apply('{0:.2%}'.format)\n",
    "    kstable.index = range(1,11)\n",
    "    kstable.index.rename('Decile', inplace=True)\n",
    " #   data=data.drop(['target0','bucket'],axis=1)\n",
    "    pd.set_option('display.max_columns', 9)\n",
    "    print(kstable)\n",
    "    maxi= max(kstable['KS'])\n",
    "    #Display KS\n",
    "   # from colorama import Fore\n",
    "    #print(Fore.RED + \"KS is \" + str(max(kstable['KS']))+\"%\"+ \" at decile \" + str((kstable.index[kstable['KS']==max(kstable['KS'])][0])))\n",
    "    return( maxi )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        min_prob  max_prob  events  nonevents event_rate nonevent_rate  \\\n",
      "Decile                                                                   \n",
      "1       0.933425  0.996744     424          0     15.46%         0.00%   \n",
      "2       0.590759  0.929501    1684        154     61.42%         1.78%   \n",
      "3       0.184364  0.582151     418        717     15.24%         8.28%   \n",
      "4       0.082108  0.182539      81       1082      2.95%        12.50%   \n",
      "5       0.049464  0.081706      39       1018      1.42%        11.76%   \n",
      "6       0.038272  0.049393      25       1024      0.91%        11.83%   \n",
      "7       0.028460  0.038198      28       1255      1.02%        14.50%   \n",
      "8       0.022139  0.028435      27       1088      0.98%        12.57%   \n",
      "9       0.017661  0.022075       8       1132      0.29%        13.08%   \n",
      "10      0.005292  0.017606       8       1187      0.29%        13.71%   \n",
      "\n",
      "       cum_eventrate cum_noneventrate    KS  \n",
      "Decile                                       \n",
      "1             15.46%            0.00%  15.5  \n",
      "2             76.88%            1.78%  75.1  \n",
      "3             92.12%           10.06%  82.1  \n",
      "4             95.08%           22.56%  72.5  \n",
      "5             96.50%           34.32%  62.2  \n",
      "6             97.41%           46.15%  51.3  \n",
      "7             98.43%           60.64%  37.8  \n",
      "8             99.42%           73.21%  26.2  \n",
      "9             99.71%           86.29%  13.4  \n",
      "10           100.00%          100.00%   0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "new_y=model.predict_proba(X_train)\n",
    "\n",
    "df = pd.DataFrame(new_y,columns=['good', 'bad'])\n",
    "\n",
    "\n",
    "df2=df.reset_index(drop=True).merge(y_train.reset_index(drop=True), left_index=True, right_index=True)\n",
    "df3=df2.reset_index(drop=True).merge(X_train.reset_index(drop=True), left_index=True, right_index=True)\n",
    "\n",
    "mydf =ks(data=df3,target=\"resposta\", prob=\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival(avg_monthly_hrs,last_evaluation, n_projects, satisfaction):\n",
    "    df = pd.DataFrame.from_dict({'avg_monthly_hrs': [avg_monthly_hrs],'last_evaluation': [last_evaluation],\n",
    "                                 'n_projects': [n_projects],'satisfaction': [satisfaction]\n",
    "                                })\n",
    "    pred = model.predict_proba(df)[0]\n",
    "    return {'Permanece na empresa': float(pred[0]), 'Sai da empersa': float(pred[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Permanece na empresa': 0.9718173742294312, 'Sai da empersa': 0.02818259969353676}\n"
     ]
    }
   ],
   "source": [
    "print(predict_survival(180,0.2,3,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/hosted (NEW!)\n",
      "Running on External URL: https://39146.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://39146.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16c4703d948>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "avg_monthly_hrs = gr.inputs.Slider(minimum=49, maximum=310, default=180, label=\"Horas trabalhadas\")\n",
    "last_evaluation =gr.inputs.Slider(minimum=0, maximum=1, default=0.5, label=\"Última Avaliação\")\n",
    "n_projects = gr.inputs.Radio([ 1, 2,3,4,5,6], label=\"Número de projetos\")\n",
    "satisfaction = gr.inputs.Slider(minimum=0, maximum=1, default=0.5, label=\"Satisfação\")\n",
    "\n",
    "gr.Interface(predict_survival, [avg_monthly_hrs,\n",
    "                                last_evaluation, n_projects,satisfaction\n",
    "                               ], \"label\", live=True).launch(share=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting explainerdashboard\n",
      "  Using cached explainerdashboard-0.3.0.1-py3-none-any.whl (268 kB)\n",
      "Collecting shortuuid\n",
      "  Using cached shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: waitress in c:\\users\\fgeba\\appdata\\roaming\\python\\python37\\site-packages (from explainerdashboard) (1.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from explainerdashboard) (1.18.2)\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\85\\e9\\f4\\033d9bd19fe04ba8b3b41b6cfaec3c4634e85bdcdd82858ff3\\dash-1.19.0-py3-none-any.whl\n",
      "Requirement already satisfied: joblib in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from explainerdashboard) (0.14.1)\n",
      "Collecting shap>=0.37\n",
      "  Using cached shap-0.38.1-cp37-cp37m-win_amd64.whl (413 kB)\n",
      "Collecting flask-simplelogin\n",
      "  Using cached flask_simplelogin-0.0.7-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: click in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from explainerdashboard) (7.0)\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\59\\bb\\83\\6b7c816105cc26e388a8166f43447fc26d350ee3b808209ea8\\dtreeviz-1.1.4-py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from explainerdashboard) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from explainerdashboard) (0.23.2)\n",
      "Collecting dash-bootstrap-components\n",
      "  Using cached dash_bootstrap_components-0.11.1-py2.py3-none-any.whl (187 kB)\n",
      "Collecting jupyter-dash\n",
      "  Using cached jupyter_dash-0.4.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: oyaml in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from explainerdashboard) (1.0)\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\19\\b2\\02\\3c3f05988ff92f02c52ce4e081859d423537e8e9b13f673c02\\dash_auth-1.4.1-py3-none-any.whl\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\02\\a5\\de\\374685270e68a4a49867f9c0ddd477a85e09eb1a2cb0998f92\\dash_core_components-1.15.0-py3-none-any.whl\n",
      "Requirement already satisfied: plotly in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from dash>=1.19->explainerdashboard) (4.14.1)\n",
      "Requirement already satisfied: future in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from dash>=1.19->explainerdashboard) (0.18.2)\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\99\\cb\\33\\e4a2c51ecfcaa8ebeb37c1835d878860b76b2101833e31b434\\dash_html_components-1.1.2-py3-none-any.whl\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\bb\\53\\d4\\13f2804207aada48c7182dfb85e03b50feecdf601e50ff5603\\dash_renderer-1.9.0-py3-none-any.whl\n",
      "Processing c:\\users\\fgeba\\appdata\\local\\pip\\cache\\wheels\\57\\bc\\76\\fd2c8bfa63b7360f1dbf9814fb622ec0c7bec0107e6032e8fd\\dash_table-4.11.2-py3-none-any.whl\n",
      "Requirement already satisfied: Flask>=1.0.4 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from dash>=1.19->explainerdashboard) (1.1.1)\n",
      "Collecting flask-compress\n",
      "  Using cached Flask_Compress-1.8.0-py3-none-any.whl (7.2 kB)\n",
      "Collecting slicer==0.0.7\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from shap>=0.37->explainerdashboard) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from shap>=0.37->explainerdashboard) (1.4.1)\n",
      "Requirement already satisfied: numba in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from shap>=0.37->explainerdashboard) (0.48.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from shap>=0.37->explainerdashboard) (4.54.1)\n",
      "Collecting flask_wtf\n",
      "  Using cached Flask_WTF-0.14.3-py2.py3-none-any.whl (13 kB)\n",
      "Collecting colour\n",
      "  Using cached colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fgeba\\appdata\\roaming\\python\\python37\\site-packages (from dtreeviz>=1.1.4->explainerdashboard) (3.0.3)\n",
      "Requirement already satisfied: pytest in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from dtreeviz>=1.1.4->explainerdashboard) (5.3.5)\n",
      "Requirement already satisfied: graphviz>=0.9 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from dtreeviz>=1.1.4->explainerdashboard) (0.15)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pandas>=1.2->explainerdashboard) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pandas>=1.2->explainerdashboard) (2019.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from scikit-learn->explainerdashboard) (2.1.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-dash->explainerdashboard) (1.3.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-dash->explainerdashboard) (7.12.0)\n",
      "Collecting ansi2html\n",
      "  Using cached ansi2html-1.6.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-dash->explainerdashboard) (2.25.1)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-dash->explainerdashboard) (5.1.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from oyaml->explainerdashboard) (5.3)\n",
      "Collecting chart-studio>=1.0.0\n",
      "  Using cached chart_studio-1.1.0-py3-none-any.whl (64 kB)\n",
      "Collecting flask-seasurf\n",
      "  Using cached Flask_SeaSurf-0.3.0-py3-none-any.whl (8.1 kB)\n",
      "Collecting ua-parser\n",
      "  Using cached ua_parser-0.10.0-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: itsdangerous>=1.1.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from dash-auth->explainerdashboard) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from plotly->dash>=1.19->explainerdashboard) (1.12.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.19->explainerdashboard) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.19->explainerdashboard) (2.11.1)\n",
      "Collecting brotli\n",
      "  Using cached Brotli-1.0.9-cp37-cp37m-win_amd64.whl (365 kB)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from numba->shap>=0.37->explainerdashboard) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from numba->shap>=0.37->explainerdashboard) (45.2.0.post20200210)\n",
      "Collecting WTForms\n",
      "  Using cached WTForms-2.3.3-py2.py3-none-any.whl (169 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from matplotlib->dtreeviz>=1.1.4->explainerdashboard) (0.10.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (1.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (1.5.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from pytest->dtreeviz>=1.1.4->explainerdashboard) (0.4.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (4.3.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (0.1.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (4.4.1)\n",
      "Requirement already satisfied: pygments in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (2.5.2)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (0.14.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (3.0.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash->explainerdashboard) (0.7.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from requests->jupyter-dash->explainerdashboard) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from requests->jupyter-dash->explainerdashboard) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from requests->jupyter-dash->explainerdashboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from requests->jupyter-dash->explainerdashboard) (1.25.8)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash->explainerdashboard) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash->explainerdashboard) (5.3.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=1.19->explainerdashboard) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->dtreeviz>=1.1.4->explainerdashboard) (2.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->jupyter-dash->explainerdashboard) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->jupyter-dash->explainerdashboard) (0.5.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter-dash->explainerdashboard) (4.6.1)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter-dash->explainerdashboard) (227)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\fgeba\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter-dash->explainerdashboard) (18.1.1)\n",
      "Installing collected packages: shortuuid, dash-core-components, dash-html-components, dash-renderer, dash-table, brotli, flask-compress, dash, slicer, shap, WTForms, flask-wtf, flask-simplelogin, colour, dtreeviz, dash-bootstrap-components, ansi2html, jupyter-dash, chart-studio, flask-seasurf, ua-parser, dash-auth, explainerdashboard\n",
      "Successfully installed WTForms-2.3.3 ansi2html-1.6.0 brotli-1.0.9 chart-studio-1.1.0 colour-0.1.5 dash-1.19.0 dash-auth-1.4.1 dash-bootstrap-components-0.11.1 dash-core-components-1.15.0 dash-html-components-1.1.2 dash-renderer-1.9.0 dash-table-4.11.2 dtreeviz-1.1.4 explainerdashboard-0.3.0.1 flask-compress-1.8.0 flask-seasurf-0.3.0 flask-simplelogin-0.0.7 flask-wtf-0.14.3 jupyter-dash-0.4.0 shap-0.38.1 shortuuid-1.0.1 slicer-0.0.7 ua-parser-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts dash-generate-components.exe and renderer.exe are installed in 'C:\\Users\\fgeba\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script ansi2html.exe is installed in 'C:\\Users\\fgeba\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts explainerdashboard.exe and explainerhub.exe are installed in 'C:\\Users\\fgeba\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install explainerdashboard --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: shap=='guess' so guessing for XGBClassifier shap='tree'...\n",
      "Detected XGBClassifier model: Changing class type to XGBClassifierExplainer...\n",
      "Note: model_output=='probability'. For XGBClassifier shap values normally get calculated against X_background, but paramater X_background=None, so using X instead\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model, X, model_output='probability', feature_perturbation='interventional')...\n",
      "Note: Shap interaction values will not be available. If shap values in probability space are not necessary you can pass model_output='logodds' to get shap values in logodds without the need for a background dataset and also working shap interaction values...\n"
     ]
    }
   ],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "explainer = ClassifierExplainer(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "For this type of model and model_output interactions don't work, so setting shap_interaction=False...\n",
      "Generating layout...\n",
      "Calculating shap values...\n",
      "Generating xgboost model dump...\n",
      "Calculating dependencies...\n",
      "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
      "Calculating pred_percentiles...\n",
      "Calculating prediction probabilities...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Starting ExplainerDashboard on http://localhost:8050\n",
      "Dash is running on http://0.0.0.0:8050/\n",
      "\n",
      "Dash is running on http://0.0.0.0:8050/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
